{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vectorization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXwhKKNvldUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5d899bca-db1f-4679-a1ff-e95a3f706fcc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import collections, re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "!pip3 install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1MpjqY0lkwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9bd49e24-0690-4a8c-abf1-6f5a4aef6c6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K5KI3OklnU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/My Drive/NLP project/fake_job_postings.csv\",encoding='latin-1') #you need to change the path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlW3_p-lltQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "BAD_SYMBOLS_RE = re.compile('[^a-z ]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() # lowercase text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text) \n",
        "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
        "    return text\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z90antRfl0hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[['company_profile','description']]=df[['company_profile','description']].replace({np.NAN: \"Not provided\"})\n",
        "df['company_profile']=df['company_profile'].astype(str)\n",
        "df['company_profile'] = df['company_profile'].apply(clean_text)\n",
        "df['description']=df['description'].astype(str)\n",
        "df['description'] = df['description'].apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlcpaEycmXfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "91d00064-7cec-41e4-82dc-058d90dbaac2"
      },
      "source": [
        "df[['company_profile','description']]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company_profile</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>food weve created groundbreaking awardwinning ...</td>\n",
              "      <td>food fastgrowing james beard awardwinning onli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>seconds worlds cloud video production service ...</td>\n",
              "      <td>organised focused vibrant awesomedo passion cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>valor services provides workforce solutions me...</td>\n",
              "      <td>client located houston actively seeking experi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>passion improving quality life geography heart...</td>\n",
              "      <td>company esri environmental systems research in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spotsource solutions llc global human capital ...</td>\n",
              "      <td>job title itemization review managerlocation f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17875</th>\n",
              "      <td>vend looking awesome new talent come join us y...</td>\n",
              "      <td>case first time youve visited website vend awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17876</th>\n",
              "      <td>weblinc ecommerce platform services provider f...</td>\n",
              "      <td>payroll accountant focus primarily payroll fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17877</th>\n",
              "      <td>provide full time permanent positions many med...</td>\n",
              "      <td>experienced project cost control staff enginee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17878</th>\n",
              "      <td>provided</td>\n",
              "      <td>nemsia studios looking experienced visualgraph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17879</th>\n",
              "      <td>vend looking awesome new talent come join us y...</td>\n",
              "      <td>wevend award winning web based point sale soft...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17880 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         company_profile                                        description\n",
              "0      food weve created groundbreaking awardwinning ...  food fastgrowing james beard awardwinning onli...\n",
              "1      seconds worlds cloud video production service ...  organised focused vibrant awesomedo passion cu...\n",
              "2      valor services provides workforce solutions me...  client located houston actively seeking experi...\n",
              "3      passion improving quality life geography heart...  company esri environmental systems research in...\n",
              "4      spotsource solutions llc global human capital ...  job title itemization review managerlocation f...\n",
              "...                                                  ...                                                ...\n",
              "17875  vend looking awesome new talent come join us y...  case first time youve visited website vend awa...\n",
              "17876  weblinc ecommerce platform services provider f...  payroll accountant focus primarily payroll fun...\n",
              "17877  provide full time permanent positions many med...  experienced project cost control staff enginee...\n",
              "17878                                           provided  nemsia studios looking experienced visualgraph...\n",
              "17879  vend looking awesome new talent come join us y...  wevend award winning web based point sale soft...\n",
              "\n",
              "[17880 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIFxbEd8I0Ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6f21bbbe-58d4-4de3-d06e-f6c54a7a40a5"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_indices, test_indices, y_train, y_test = train_test_split(np.arange(len(df)), df['fraudulent'],\n",
        "                                                    stratify=df['fraudulent'], \n",
        "                                                    test_size=0.3,random_state=0)\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_resampled, y_resampled = ros.fit_resample(np.array(train_indices).reshape(-1, 1), df.iloc[train_indices]['fraudulent'])\n",
        "X_resampled=X_resampled.flatten()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj-OrKNgMaTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_indices=X_resampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJX30EVxKeD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=3000, ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(df[\"description\"]).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyJXPAOaIdTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidfconverter = TfidfTransformer()\n",
        "X = tfidfconverter.fit_transform(X).toarray()\n",
        "X_train=X[train_indices]\n",
        "X_test=X[test_indices]\n",
        "Y_train=df['fraudulent'][train_indices]\n",
        "Y_test=df['fraudulent'][test_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOFSNa9gJp8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cdde0d13-7e17-425a-8ecd-3555ea54df8d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4847  257]\n",
            " [  59  201]]\n",
            "0.5598885793871866\n",
            "0.9410887397464579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ2HKFY6Q9Gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "62104f48-3296-440a-dfd2-883dd494635d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5087   17]\n",
            " [ 109  151]]\n",
            "0.705607476635514\n",
            "0.9765100671140939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgKK-HV8K5dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=3000, ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(df[\"description\"]).toarray()\n",
        "X_train=X[train_indices]\n",
        "X_test=X[test_indices]\n",
        "Y_train=df['fraudulent'][train_indices]\n",
        "Y_test=df['fraudulent'][test_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjPiSVS2MErE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "122c3806-0ff4-4180-ed9a-17fcb1a2c972"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score\n",
        "classifier = LogisticRegression(random_state=0,max_iter=4000)\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4933  171]\n",
            " [  73  187]]\n",
            "0.6051779935275081\n",
            "0.9545115585384042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7eJtE2ERifF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "143a6308-0d74-4564-dc46-468f070f8f5d"
      },
      "source": [
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5086   18]\n",
            " [ 105  155]]\n",
            "0.7159353348729792\n",
            "0.977069351230425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBKy47htMRlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_fatures=300\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(df['description'].values)\n",
        "X1 = tokenizer.texts_to_sequences(df['description'].values)\n",
        "X1 = pad_sequences(X1)\n",
        "X_train=X1[train_indices]\n",
        "X_test=X1[test_indices]\n",
        "Y_train=df['fraudulent'][train_indices]\n",
        "Y_test=df['fraudulent'][test_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWNTST0mNVT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7abbbae9-22d2-4bec-c096-f90c993f9b29"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score\n",
        "\n",
        "classifier = LogisticRegression(random_state=0, max_iter=8000)\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2915 2189]\n",
            " [ 107  153]]\n",
            "0.11760184473481934\n",
            "0.5719612229679344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnDeiYBbMAyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ab348ed8-00c8-4ac5-e22d-d60902656be5"
      },
      "source": [
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5098    6]\n",
            " [ 147  113]]\n",
            "0.5963060686015831\n",
            "0.9714765100671141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmbbw1bDStSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZQQaOsnYant",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zltH6CzrYaqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ad558ddf-363a-44fc-c6ad-7494f2c257f1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=3000, ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(df[\"company_profile\"]).toarray()\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidfconverter = TfidfTransformer()\n",
        "X = tfidfconverter.fit_transform(X).toarray()\n",
        "X_train=X[train_indices]\n",
        "X_test=X[test_indices]\n",
        "Y_train=df['fraudulent'][train_indices]\n",
        "Y_test=df['fraudulent'][test_indices]\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4278  826]\n",
            " [   3  257]]\n",
            "0.38272524199553243\n",
            "0.8454511558538405\n",
            "[[4280  824]\n",
            " [   6  254]]\n",
            "0.37967115097159937\n",
            "0.8452647278150633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GR7ziptYavk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4446e269-522b-43e5-c043-b5bdbf34c0e9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=3000, ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(df[\"company_profile\"]).toarray()\n",
        "X_train=X[train_indices]\n",
        "X_test=X[test_indices]\n",
        "Y_train=df['fraudulent'][train_indices]\n",
        "Y_test=df['fraudulent'][test_indices]\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score\n",
        "classifier = LogisticRegression(random_state=0,max_iter=4000)\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4276  828]\n",
            " [   2  258]]\n",
            "0.3833580980683507\n",
            "0.8452647278150633\n",
            "[[4280  824]\n",
            " [   4  256]]\n",
            "0.38208955223880603\n",
            "0.8456375838926175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2uC0hnaYauN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "45b8902c-77e8-44f9-e463-865d40065b8f"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_fatures=30000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(df['company_profile'].values)\n",
        "X1 = tokenizer.texts_to_sequences(df['company_profile'].values)\n",
        "X1 = pad_sequences(X1)\n",
        "X_train=X1[train_indices]\n",
        "X_test=X1[test_indices]\n",
        "Y_train=df['fraudulent'][train_indices]\n",
        "Y_test=df['fraudulent'][test_indices]\n",
        "\n",
        "classifier = LogisticRegression(random_state=0, max_iter=8000)\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(Y_test,y_pred))\n",
        "print(f1_score(Y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[3530 1574]\n",
            " [  19  241]]\n",
            "0.23228915662650598\n",
            "0.7030201342281879\n",
            "[[4279  825]\n",
            " [   6  254]]\n",
            "0.3793876026885736\n",
            "0.8450782997762863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798stcwOIudG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}