{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baselines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFRaJXotVie-",
        "colab_type": "code",
        "outputId": "9efd9795-3f37-4ba2-f812-897db227fa17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PjG4P7yVrKY",
        "colab_type": "code",
        "outputId": "3f913f85-87a1-429f-9366-e2d84e8c3b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import collections, re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "!pip3 install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "from keras.layers import  CuDNNLSTM "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4neYPDV0sD",
        "colab_type": "code",
        "outputId": "969094bd-3dce-420c-cea0-32b97740e18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ1e1W5zWOzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_data=pd.read_csv(\"/content/drive/My Drive/NLP project/final_clean_data.csv\",encoding='latin-1') #you need to change the path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuDCPIxiLMkh",
        "colab_type": "code",
        "outputId": "ee297783-6fa9-40ce-ccfc-7adbfa9ebf76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_indices, test_indices, y_train, y_test = train_test_split(np.arange(len(clean_data)), clean_data['fraudulent'],\n",
        "                                                    stratify=clean_data['fraudulent'], \n",
        "                                                    test_size=0.3,random_state=0)\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_resampled, y_resampled = ros.fit_resample(np.array(train_indices).reshape(-1, 1), clean_data.iloc[train_indices]['fraudulent'])\n",
        "X_resampled=X_resampled.flatten()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "226DP-arLEVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_text=clean_data.drop(['title','job_id','company_profile','description','fraudulent','Ambiguous Range','missing_salary','missing_stat','ambiguous_salary'], axis=1)\n",
        "non_text2=clean_data.drop(['title','job_id','company_profile','description','fraudulent',], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GneQC0GbLmHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_fatures = 3000\n",
        "clean_data['description']=clean_data['description'].astype(str)\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(clean_data['description'].values)\n",
        "X1 = tokenizer.texts_to_sequences(clean_data['description'].values)\n",
        "X1 = pad_sequences(X1)\n",
        "\n",
        "max_fatures = 3000\n",
        "clean_data['company_profile']=clean_data['description'].astype(str)\n",
        "tokenizer1 = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer1.fit_on_texts(clean_data['company_profile'].values)\n",
        "X2 = tokenizer.texts_to_sequences(clean_data['company_profile'].values)\n",
        "X2 = pad_sequences(X1)\n",
        "\n",
        "combined=np.concatenate((X1, X2), axis=1)\n",
        "combined=np.concatenate((combined, non_text), axis=1)\n",
        "combined2=np.concatenate((combined, non_text2), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgODLTH2O3KN",
        "colab_type": "code",
        "outputId": "79148d2f-872f-45d0-df2e-1446741663a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score, precision_score, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(max_iter=3000)\n",
        "classifier.fit(combined[X_resampled], y_resampled)\n",
        "y_pred = classifier.predict(combined[test_indices])\n",
        "print(f1_score(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(precision_score(y_test,y_pred))\n",
        "print(recall_score(y_test,y_pred))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2410291130670278\n",
            "0.7910141685309471\n",
            "0.14626129827444537\n",
            "0.6846153846153846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWPcVYvNZYqq",
        "colab_type": "code",
        "outputId": "81f5c0cd-4c65-4285-e30f-4889f8ba1548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score, precision_score, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(max_iter=3000)\n",
        "classifier.fit(combined2[X_resampled], y_resampled)\n",
        "y_pred = classifier.predict(combined2[test_indices])\n",
        "print(f1_score(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(precision_score(y_test,y_pred))\n",
        "print(recall_score(y_test,y_pred))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24769992922859163\n",
            "0.801826994780015\n",
            "0.15177797051170858\n",
            "0.6730769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TrjwGykOYgq",
        "colab_type": "code",
        "outputId": "e0e03d6f-e2f1-4315-c7e2-eba79f92fb2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=0,max_depth=20,n_estimators=1000)\n",
        "classifier.fit(combined[X_resampled], y_resampled)\n",
        "y_pred = classifier.predict(combined[test_indices])\n",
        "print(f1_score(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(precision_score(y_test,y_pred))\n",
        "print(recall_score(y_test,y_pred))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6351706036745406\n",
            "0.9740865026099925\n",
            "1.0\n",
            "0.4653846153846154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjOSzQL3Zd-S",
        "colab_type": "code",
        "outputId": "e95b74f9-fe60-4536-c9b6-8f171b1b3f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=0,max_depth=20,n_estimators=1000)\n",
        "classifier.fit(combined2[X_resampled], y_resampled)\n",
        "y_pred = classifier.predict(combined2[test_indices])\n",
        "print(f1_score(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(precision_score(y_test,y_pred))\n",
        "print(recall_score(y_test,y_pred))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6528497409326425\n",
            "0.9750186428038777\n",
            "1.0\n",
            "0.4846153846153846\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}